{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')    \n",
    "    \n",
    "type(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', (65, 'the A')), ('A', (66, 'the A')), ('C', (19, 'the C'))]\n",
      "[('A', (65, 'the A')), ('A', (66, 'the A')), ('E', (32, None)), ('C', (19, 'the C')), ('B', (18, None))]\n",
      "[('A', (65, 'the A')), ('A', (66, 'the A')), ('C', (19, 'the C')), ('F', (None, 'the F')), ('F', (None, 'the real F'))]\n"
     ]
    }
   ],
   "source": [
    "# joins\n",
    "data1 = [('A',65),('C',19),('E',32),('B',18),('A',66)]\n",
    "distData1 = sc.parallelize(data1,2)\n",
    "data2 = [('A','the A'),('C','the C'),('F','the F'),('F','the real F')]\n",
    "distData2 = sc.parallelize(data2,2)\n",
    "print distData1.join(distData2).collect()\n",
    "print distData1.leftOuterJoin(distData2).collect()\n",
    "print distData1.rightOuterJoin(distData2).collect()\n",
    "#print distData1.cartesian(distData2).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nintendo of America (EEUU) tiene información de ventas de videojuegos físicas mensuales totalizadas en EEUU\n",
    "las cuales se realizan en cadenas de tiendas de videojuegos en el siguiente RDD: (id_videojuego, id_tienda, mes,\n",
    "anio, total_ventas_mensuales). Por otro lado tenemos un RDD con información de las tiendas y de su\n",
    "ubicación (id_tienda, direccion, latitud, longitud, codigo_postal, estado).\n",
    "Con esta información escribir un programa en pySpark para obtener la tienda que realizó menor cantidad de\n",
    "ventas en el estado de “Georgia” en todo el año 2017. (***) (15 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas = { (5678,tienda04,julio,2017,610)...}  tiendas= {tienda04, cochababba 2020, 60,-60,1070,Georgia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede hacer un join? de que manera\n",
    "\n",
    "ventas.map(lambda x: (x[1],(x[3],x[4])))\n",
    "tiendas.map(lambda x: (x[0],(x[5])))\n",
    "ventas.join(tiendas)\\\n",
    ".filter(lambda x: (x[1][0] == '2017') & ('Geogia' in x[1][2]))\\\n",
    ".reduce(lambda x,y: x if x[1][1] < y[1][1] else y )\n",
    "\n",
    "(tiendaid, (2017,numerodeventas,Georgia))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Una red social almacena el contenido de los chats entre sus usuarios\n",
    "en un RDD que tiene registros con el siguiente formato: (chat_id,\n",
    "user_id, nickname, text). Queremos saber cuál es el usuario (user_id)\n",
    "que mas preguntas hace en sus chats, contabilizamos una pregunta por\n",
    "cada caracter “?” que aparezca en el campo text. Programar en Spark\n",
    "un programa que identifique al usuario preguntón. (*) (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = {(1,1,juan, blablabla?)....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter(lambda x: '?' in x[3])\\\n",
    ".map(lambda x: (x[2],x[3].count('?')))\\\n",
    ".reduceByKey(lambda x,y: x+y)\\\n",
    ".reduce(lambda x,y: x if x[1]>y[1] else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) UBER almacena en un cluster todos los datos sobre el movimiento y\n",
    "viajes de todos sus vehículos. Existe un proceso que nos devuelve un\n",
    "RDD llamado trip_summary con los siguientes campos: (driver_id,\n",
    "car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled),\n",
    "Programar usando Py Spark un programa que nos indique cual fue el\n",
    "conductor con mayor promedio de distancia recorrida por viaje para\n",
    "Abril de 2016. (***) (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary = (driver_id,car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter(lambda x: x[4][6]=='201604')\\\n",
    ".map(lambda x: x[0],(1,x[5]))\\\n",
    ".reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\\\n",
    ".reduce(lambda x,y: x if x[1][1]*y[1][0]>y[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Un telescopio registra automaticamente la luminosidad de distintas\n",
    "estrellas generando un RDD con registros de tipo (star_id,\n",
    "magnitude,spectral_type, timestamp). Queremos obtener un listado de\n",
    "estrellas que tienen el mismo tipo espectral e igual promedio de\n",
    "magnitud una vez redondeado el mismo a un decimal. El resultado\n",
    "debe ser una lista en donde cada elemento de la lista es una lista de ids\n",
    "de estrellas similares. (***) (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(star_id,magnitude,spectral_type, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.map(lambda x:(x[0],(1,x[1],x[2])))\\\n",
    ".reduceByKey(lambda x,y:(x[0]+y[0],x[1]+y[1]))\\\n",
    ".map(lambda x: ((round(float(x[1][1]/x[1][0]),1),x[1][2]),x[0]))\\\n",
    ".groupByKey()\\\n",
    ".map(lambda x: (x[0],list(x[1])))\\\n",
    ".collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
